{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LanguageModeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "moWB9udaKesP"
      },
      "source": [
        "Your task is to train *character-level* language models. \n",
        "You will train unigram, bigram, and trigram character level models on a collection of books from Project Gutenberg. You will then use these trained English language models to distinguish English documents from Brazilian Portuguese documents in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-nRJni2wekAI",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gHFJmuftHJld",
        "outputId": "289fa083-cf5b-44fe-e830-7ecd7f8228f5",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import httpimport\n",
        "\n",
        "with httpimport.remote_repo(['lm_helper'], 'https://raw.githubusercontent.com/jasoriya/CS6120-PS2-support/master/utils/'):\n",
        "  from lm_helper import get_train_data, get_test_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\sayan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data] Downloading package gutenberg to\n",
            "[nltk_data]     C:\\Users\\sayan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n",
            "[nltk_data] Downloading package brown to\n",
            "[nltk_data]     C:\\Users\\sayan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\brown.zip.\n",
            "[nltk_data] Downloading package mac_morpho to\n",
            "[nltk_data]     C:\\Users\\sayan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\mac_morpho.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8U0UCuyHQkai"
      },
      "source": [
        "This code loads the training and test data. Each dataset is a list of books. Each book contains a list of sentences, and each sentence contains a list of words. For building a character language model, you should join the words of a sentence together with a space character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6x0pfuiEChTh",
        "colab": {}
      },
      "source": [
        "# get the train and test data\n",
        "train = get_train_data()\n",
        "test, test_files = get_test_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_WAO9VjFLArq"
      },
      "source": [
        "## 1.1\n",
        "Collect statistics on the unigram, bigram, and trigram character counts.\n",
        "\n",
        "If your machine takes a long time to perform this computation, you may save these counts to files in your github repository and load them on request. This is not necessary, however."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Oh4VOoiSIoUF",
        "outputId": "bd35342f-5aa4-4d55-8936-7814e5f5a497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "TRAIN,DEV=train_test_split(train,test_size=0.2, random_state=42)\n",
        "corpus=[]\n",
        "for i in range(len(TRAIN)):\n",
        "  for j in range(len(TRAIN[i])):\n",
        "    corpus.append((re.sub(\"[\\x1a]+\", ' ',\" \".join(TRAIN[i][j])).lstrip().rstrip()))\n",
        "\n",
        "c1,c2,c3=dict(),dict(),dict()\n",
        "\n",
        "cv1=CountVectorizer(ngram_range=(1,1),analyzer='char')\n",
        "x1=cv1.fit_transform(corpus)\n",
        "\n",
        "t1=np.array(np.sum(x1,axis=0))[0]\n",
        "for i,name in enumerate(cv1.get_feature_names()):\n",
        "  c1[name]=t1[i] # word and count\n",
        " \n",
        "#removing unigrams that have a count <100\n",
        "rep=[]\n",
        "tot=0\n",
        "for a in c1:\n",
        "  if c1[a]<100:\n",
        "    tot +=c1[a]\n",
        "    rep.append(a)\n",
        "\n",
        "c1['µ']=tot # unknown token since it doesnt appear int the docs\n",
        "\n",
        "for i in rep:\n",
        "  del c1[i]\n",
        "\n",
        "corpus2=[]\n",
        "for sent in corpus:\n",
        "  corpus2.append(re.sub('[/$/&>/`/æ]',\"µ\" ,sent))\n",
        "\n",
        "# removed tokens with values less than 100 and replaced with special token\n",
        "cv1=CountVectorizer(ngram_range=(1,1),analyzer='char')\n",
        "cv2=CountVectorizer(ngram_range=(2,2),analyzer='char')\n",
        "cv3=CountVectorizer(ngram_range=(3,3),analyzer='char')\n",
        "x1=cv1.fit_transform(corpus2)\n",
        "x2=cv2.fit_transform(corpus2)\n",
        "x3=cv3.fit_transform(corpus2)\n",
        "\n",
        "t1=np.array(np.sum(x1,axis=0))[0]\n",
        "for i,name in enumerate(cv1.get_feature_names()):\n",
        "  c1[name]=t1[i] \n",
        "\n",
        "t2=np.array(np.sum(x2,axis=0))[0]\n",
        "for i,name in enumerate(cv2.get_feature_names()):\n",
        "  c2[name]=t2[i]\n",
        "\n",
        "t3=np.array(np.sum(x3,axis=0))[0]\n",
        "for i,name in enumerate(cv3.get_feature_names()):\n",
        "  c3[name]=t3[i]\n",
        "\n",
        "print(\"Number of Unigrams {}\".format(len(cv1.get_feature_names())))\n",
        "print(\"Number of Bigrams {}\".format(len(cv2.get_feature_names())))\n",
        "print(\"Number of Trigrams {}\".format(len(cv3.get_feature_names())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Unigrams 54\n",
            "Number of Bigrams 884\n",
            "Number of Trigrams 8618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MUUVb21PPEPE",
        "colab": {}
      },
      "source": [
        "def generate_trigram_sent(sent):\n",
        "    tri=[]\n",
        "    for j in range(len(sent)-3):\n",
        "      tri.append(sent[j:j+3])\n",
        "    return tri\n",
        "\n",
        "\n",
        "# trying a different variant\n",
        "def uni_prob(token,a1):\n",
        "  if token not in set(a1.keys()) :\n",
        "    return a1['µ']/np.array(list(a1.values())).sum() # denominator represnts the total number of characters in the training set\n",
        "  else :\n",
        "    return a1[token]/np.array(list(a1.values())).sum()\n",
        "\n",
        "def bi_prob(token,a2,a1):\n",
        "  if token not in set(a2.keys()):\n",
        "    return 0\n",
        "  else:\n",
        "    return a2[token]/a1[token[:1]]\n",
        "\n",
        "def tri_prob(token,a3,a2,a1):\n",
        "  if token not in set(a3.keys()):\n",
        "    return 0\n",
        "  else:\n",
        "    return a3[token]/a2[token[:2]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A0jjfRdbPEUM",
        "colab": {}
      },
      "source": [
        "def perplexity(corp,la1,la2,la3,a1,a2,a3): # corp can be the whole test set or dev set  \n",
        "    perplexity=[]\n",
        "    for doc in corp: # picking single documents\n",
        "        #print(\"doc\")\n",
        "    \n",
        "        dd=CountVectorizer(ngram_range=(1,1),analyzer='char')\n",
        "        gg=dd.fit_transform(doc)\n",
        "        tt=dict()\n",
        "        tp1=np.array(np.sum(gg,axis=0))[0]\n",
        "        for i,name in enumerate(dd.get_feature_names()):\n",
        "          tt[name]=tp1[i] # word and count\n",
        "        char=np.array(list(tt.values())).sum() # refers to M # total number of characters in a document\n",
        "\n",
        "        # real calculations begin\n",
        "\n",
        "        log_prob=0\n",
        "        for sent in doc: # refers to each document fro the dev set or test set # loops over all thesentences in the document\n",
        "          trigrams=generate_trigram_sent(sent) # generates trigrams for the given sentence\n",
        "          for tri_gram in trigrams: # loops over all the characters in a sentence\n",
        "              words = tri_gram     # trigram\n",
        "              bi_word = words[-2:] # bigram\n",
        "              uniword = words[-1]  # unigram\n",
        "\n",
        "              prob=float(la1) * uni_prob(uniword,a1) + float(la2) * bi_prob(bi_word,a2,a1) + float(la3) * tri_prob(words,a3,a2,a1)\n",
        "              log_prob += np.log2(prob)\n",
        "\n",
        "        l=log_prob/char\n",
        "        perp=pow(2,-l)\n",
        "        print(perp)\n",
        "        perplexity.append(perp)\n",
        "    return(perplexity)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xGq4Z8MyPjGN",
        "colab": {}
      },
      "source": [
        "# preparing test set\n",
        "dev=[]\n",
        "for i in range(len(DEV)):\n",
        "  k=[]\n",
        "  for j in range(len(DEV[i])):\n",
        "    k.append((\" \".join(DEV[i][j])).lstrip().rstrip())\n",
        "  dev.append(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "74WnDoZdPEXW",
        "outputId": "0d6d0063-e09b-4dbf-98f7-64c773446131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "vals=[(0.3,0.3,0.4),(0.1,0.1,0.8),(0.05,0.05,0.9)]\n",
        "gs=pd.DataFrame(index=np.arange(10),columns=['l1','l2','l3','perplexity on Dev1','perplexity on Dev2','perplexity on Dev3','perplexity on Dev4'])\n",
        "for index,(a,b,c) in enumerate(vals):\n",
        "  print(index)\n",
        "  pp=perplexity(dev,a,b,c,c1,c2,c3)\n",
        "  gs.iloc[index,0]=a\n",
        "  gs.iloc[index,1]=b\n",
        "  gs.iloc[index,2]=c\n",
        "  gs.iloc[index,3]=pp[0]\n",
        "  gs.iloc[index,4]=pp[1]\n",
        "  gs.iloc[index,5]=pp[2]\n",
        "  gs.iloc[index,6]=pp[3]\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "9.813588164958933\n",
            "9.406214996393329\n",
            "9.725194606093474\n",
            "9.260701066184927\n",
            "1\n",
            "8.716136989029756\n",
            "8.285508611518384\n",
            "8.705132744577154\n",
            "8.259456370655682\n",
            "2\n",
            "8.76291047726098\n",
            "8.289438931279633\n",
            "8.750331381329111\n",
            "8.31421348518957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PyWxo0P7sQ3V",
        "outputId": "2a079864-1834-4b6e-b1ec-b81c803759c5",
        "colab": {}
      },
      "source": [
        "\n",
        "vals=[(0.9,0.05,0.05),(0.05,0.9,0.05),(0.15,0.15,0.7)]\n",
        "for index,(a,b,c) in enumerate(vals):\n",
        "  print(index)\n",
        "  pp=perplexity(dev,a,b,c,c1,c2,c3)\n",
        "  gs.iloc[index+3,0]=a\n",
        "  gs.iloc[index+3,1]=b\n",
        "  gs.iloc[index+3,2]=c\n",
        "  gs.iloc[index+3,3]=pp[0]\n",
        "  gs.iloc[index+3,4]=pp[1]\n",
        "  gs.iloc[index+3,5]=pp[2]\n",
        "  gs.iloc[index+3,6]=pp[3]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "16.166323735910773\n",
            "15.584765299412037\n",
            "15.75528288514541\n",
            "15.277191065067907\n",
            "1\n",
            "11.687808575041446\n",
            "11.101164440327587\n",
            "11.364067567752691\n",
            "10.825074660256876\n",
            "2\n",
            "8.84456655594152\n",
            "8.432693964934181\n",
            "8.823073546257332\n",
            "8.373265237943288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ulQO9U-0tHrX",
        "outputId": "cb1c3c77-f12f-4a9a-eab1-e93b11227295",
        "colab": {}
      },
      "source": [
        "vals=[(0.2,0.2,0.6),(0.1,0.2,0.7),(0.2,0.1,0.7)]\n",
        "for index,(a,b,c) in enumerate(vals):\n",
        "  print(index)\n",
        "  pp=perplexity(dev,a,b,c,c1,c2,c3)\n",
        "  gs.iloc[index+6,0]=a\n",
        "  gs.iloc[index+6,1]=b\n",
        "  gs.iloc[index+6,2]=c\n",
        "  gs.iloc[index+6,3]=pp[0]\n",
        "  gs.iloc[index+6,4]=pp[1]\n",
        "  gs.iloc[index+6,5]=pp[2]\n",
        "  gs.iloc[index+6,6]=pp[3]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "9.07585218782757\n",
            "8.672069124613337\n",
            "9.037754981041642\n",
            "8.58426766942614\n",
            "1\n",
            "8.83179665800465\n",
            "8.40320982132402\n",
            "8.795475806790627\n",
            "8.347725160525366\n",
            "2\n",
            "8.902203822526706\n",
            "8.500849406990639\n",
            "8.89360758701261\n",
            "8.442758289241285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i6XOyzK_tH3E",
        "outputId": "eb86624e-cecd-4fcc-e07c-d8687d398bd2",
        "colab": {}
      },
      "source": [
        "vals=[(0.3,0.4,0.3)]\n",
        "for index,(a,b,c) in enumerate(vals):\n",
        "  print(index)\n",
        "  pp=perplexity(dev,a,b,c,c1,c2,c3)\n",
        "  gs.iloc[index+9,0]=a\n",
        "  gs.iloc[index+9,1]=b\n",
        "  gs.iloc[index+9,2]=c\n",
        "  gs.iloc[index+9,3]=pp[0]\n",
        "  gs.iloc[index+9,4]=pp[1]\n",
        "  gs.iloc[index+9,5]=pp[2]\n",
        "  gs.iloc[index+9,6]=pp[3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10.220304348961951\n",
            "9.798488483148885\n",
            "10.09251311269769\n",
            "9.61725547882338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "61U6YhhfsKUH",
        "outputId": "2b09d64b-8d25-46da-f406-d24561fbc582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "gs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>l1</th>\n",
              "      <th>l2</th>\n",
              "      <th>l3</th>\n",
              "      <th>perplexity on Dev1</th>\n",
              "      <th>perplexity on Dev2</th>\n",
              "      <th>perplexity on Dev3</th>\n",
              "      <th>perplexity on Dev4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>9.81359</td>\n",
              "      <td>9.40621</td>\n",
              "      <td>9.72519</td>\n",
              "      <td>9.2607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>8.71614</td>\n",
              "      <td>8.28551</td>\n",
              "      <td>8.70513</td>\n",
              "      <td>8.25946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.9</td>\n",
              "      <td>8.76291</td>\n",
              "      <td>8.28944</td>\n",
              "      <td>8.75033</td>\n",
              "      <td>8.31421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>16.1663</td>\n",
              "      <td>15.5848</td>\n",
              "      <td>15.7553</td>\n",
              "      <td>15.2772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.05</td>\n",
              "      <td>11.6878</td>\n",
              "      <td>11.1012</td>\n",
              "      <td>11.3641</td>\n",
              "      <td>10.8251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.7</td>\n",
              "      <td>8.84457</td>\n",
              "      <td>8.43269</td>\n",
              "      <td>8.82307</td>\n",
              "      <td>8.37327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>9.07585</td>\n",
              "      <td>8.67207</td>\n",
              "      <td>9.03775</td>\n",
              "      <td>8.58427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.7</td>\n",
              "      <td>8.8318</td>\n",
              "      <td>8.40321</td>\n",
              "      <td>8.79548</td>\n",
              "      <td>8.34773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>8.9022</td>\n",
              "      <td>8.50085</td>\n",
              "      <td>8.89361</td>\n",
              "      <td>8.44276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>10.2203</td>\n",
              "      <td>9.79849</td>\n",
              "      <td>10.0925</td>\n",
              "      <td>9.61726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     l1    l2    l3 perplexity on Dev1 perplexity on Dev2 perplexity on Dev3  \\\n",
              "0   0.3   0.3   0.4            9.81359            9.40621            9.72519   \n",
              "1   0.1   0.1   0.8            8.71614            8.28551            8.70513   \n",
              "2  0.05  0.05   0.9            8.76291            8.28944            8.75033   \n",
              "3   0.9  0.05  0.05            16.1663            15.5848            15.7553   \n",
              "4  0.05   0.9  0.05            11.6878            11.1012            11.3641   \n",
              "5  0.15  0.15   0.7            8.84457            8.43269            8.82307   \n",
              "6   0.2   0.2   0.6            9.07585            8.67207            9.03775   \n",
              "7   0.1   0.2   0.7             8.8318            8.40321            8.79548   \n",
              "8   0.2   0.1   0.7             8.9022            8.50085            8.89361   \n",
              "9   0.3   0.4   0.3            10.2203            9.79849            10.0925   \n",
              "\n",
              "  perplexity on Dev4  \n",
              "0             9.2607  \n",
              "1            8.25946  \n",
              "2            8.31421  \n",
              "3            15.2772  \n",
              "4            10.8251  \n",
              "5            8.37327  \n",
              "6            8.58427  \n",
              "7            8.34773  \n",
              "8            8.44276  \n",
              "9            9.61726  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGSu8WJkV8Qp",
        "colab_type": "text"
      },
      "source": [
        "# l1=0.1, l2=0.1,l3=0.8 performs the best"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xHxI1K0BPER2",
        "outputId": "66799724-12a5-4358-90f2-24c4c32a93a3",
        "colab": {}
      },
      "source": [
        "# preparing test set\n",
        "TEST=[]\n",
        "for i in range(len(test)):\n",
        "  k=[]\n",
        "  for j in range(len(test[i])):\n",
        "    k.append((\" \".join(test[i][j])).lstrip().rstrip())\n",
        "  TEST.append(k)\n",
        "pp=perplexity(TEST,0.1,0.1,0.8,c1,c2,c3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.602390110472822\n",
            "12.346587207317121\n",
            "10.813909384232538\n",
            "12.301324449065973\n",
            "10.334058173770245\n",
            "11.203919545977598\n",
            "10.69027776474952\n",
            "8.427348238623338\n",
            "8.316009691123016\n",
            "10.382608688528812\n",
            "13.2842284896863\n",
            "7.878219910596223\n",
            "31.078739827539465\n",
            "11.995724482059607\n",
            "11.766587432913054\n",
            "9.008044532271953\n",
            "9.475038225336784\n",
            "11.093115147087302\n",
            "29.275315310487283\n",
            "13.528705359679043\n",
            "9.43866002812946\n",
            "11.029165067546833\n",
            "9.848851805500207\n",
            "11.265702239026407\n",
            "9.580269702757967\n",
            "9.873322938600513\n",
            "12.59538793889052\n",
            "8.887262568883836\n",
            "14.079374442628644\n",
            "30.605784881330095\n",
            "12.043241208918033\n",
            "8.292701831575126\n",
            "11.441162855580028\n",
            "8.585146806628495\n",
            "31.190553557149396\n",
            "12.22428948834306\n",
            "18.949264958845284\n",
            "14.313950153699587\n",
            "9.046061131551417\n",
            "12.348565818537603\n",
            "21.43623604356789\n",
            "8.216636249350882\n",
            "10.004584595202408\n",
            "13.462176885826853\n",
            "17.994696558180927\n",
            "32.97223405368126\n",
            "11.736038500366522\n",
            "11.442336978084544\n",
            "10.280458930969614\n",
            "9.711636335097205\n",
            "31.344721364705983\n",
            "12.587931952082073\n",
            "7.921767505840446\n",
            "9.251379955404877\n",
            "10.123208366746782\n",
            "13.880419243039551\n",
            "13.561162126803827\n",
            "10.794390326679977\n",
            "13.52942952400246\n",
            "10.96309748318472\n",
            "12.9374871140546\n",
            "21.102724671318118\n",
            "10.73878051352218\n",
            "12.533544615087473\n",
            "13.017470478033829\n",
            "10.471021381549523\n",
            "11.159860406913829\n",
            "7.607643949821262\n",
            "16.708870400818796\n",
            "30.415082269756354\n",
            "9.723633240257792\n",
            "11.051312392224325\n",
            "10.62181273694891\n",
            "9.226338058257765\n",
            "10.716816634333451\n",
            "9.817012462564922\n",
            "8.67471838713967\n",
            "10.457917336855154\n",
            "14.215237093596777\n",
            "15.492124658670697\n",
            "11.97008112024097\n",
            "8.365333219281489\n",
            "10.892710445365042\n",
            "32.058847838246784\n",
            "12.349902097751498\n",
            "10.120942661534196\n",
            "11.85451882349192\n",
            "12.225326287017232\n",
            "9.239301794145018\n",
            "11.02399003505099\n",
            "8.928633405662096\n",
            "9.04555090016722\n",
            "9.040101502181004\n",
            "8.736485792699716\n",
            "9.528355787403749\n",
            "9.582122738537315\n",
            "10.731821460134485\n",
            "9.25210797035935\n",
            "10.321920050456486\n",
            "9.216462049006493\n",
            "34.07609809422748\n",
            "8.532034248090547\n",
            "9.140057313112429\n",
            "31.179321379854432\n",
            "8.888605635861426\n",
            "10.288331438876929\n",
            "14.503452266511513\n",
            "30.19654709265196\n",
            "9.684025571758534\n",
            "10.093416020375766\n",
            "9.641537290389977\n",
            "10.885428036766488\n",
            "9.301729692182704\n",
            "10.61995452476664\n",
            "10.174851607545277\n",
            "10.53257740139895\n",
            "9.944182911574535\n",
            "7.904342353828252\n",
            "8.276183889900043\n",
            "14.337878694648028\n",
            "10.272350544851653\n",
            "11.241234707988124\n",
            "8.395722883983595\n",
            "12.835588339629707\n",
            "8.174360799632892\n",
            "9.099065600230647\n",
            "13.232818382902582\n",
            "11.481596170018891\n",
            "13.04440170903703\n",
            "12.08372386692992\n",
            "32.076657919507106\n",
            "9.949578845783476\n",
            "7.846112279874536\n",
            "13.63890241061649\n",
            "12.530200855210634\n",
            "14.697287172145366\n",
            "12.239528517195208\n",
            "11.227175338308527\n",
            "10.00791015840396\n",
            "12.24488635332191\n",
            "9.921090020747815\n",
            "13.099485592120125\n",
            "11.413439787081028\n",
            "10.574119289724408\n",
            "9.785917840804771\n",
            "10.218851102152403\n",
            "16.58375145104536\n",
            "8.320410298367817\n",
            "10.289339654481045\n",
            "9.701250695219116\n",
            "9.133517386282739\n",
            "8.727451195500095\n",
            "31.668145592917945\n",
            "14.26071907928107\n",
            "10.731327784891207\n",
            "11.690457414054984\n",
            "9.722042717200697\n",
            "9.889469437719486\n",
            "31.70450151191341\n",
            "10.58892200632878\n",
            "8.20341137716001\n",
            "11.207149505298787\n",
            "10.587063264541467\n",
            "10.716301378119022\n",
            "12.306228910503537\n",
            "10.346784242499227\n",
            "10.606167984855668\n",
            "9.666185550615667\n",
            "32.24179840260452\n",
            "9.88328814553428\n",
            "31.424423280245243\n",
            "10.1829471930987\n",
            "11.6254830349662\n",
            "13.164509246406778\n",
            "13.601774614563082\n",
            "31.788426570329722\n",
            "10.547691336172019\n",
            "13.105373363910479\n",
            "9.476882209329217\n",
            "33.60631089161951\n",
            "15.34868635417737\n",
            "8.846665121056846\n",
            "32.75726314694261\n",
            "9.030851108696998\n",
            "9.602059651890091\n",
            "8.968366597707462\n",
            "14.212799799732142\n",
            "12.689183500031403\n",
            "14.333277717886675\n",
            "10.312101649586555\n",
            "11.029813387884312\n",
            "8.587982714434625\n",
            "11.202067627759224\n",
            "13.831987931321438\n",
            "12.7311624410415\n",
            "10.897505771339578\n",
            "10.155331985720458\n",
            "10.777815637969722\n",
            "9.44629145158247\n",
            "10.614876252105946\n",
            "11.060438542850333\n",
            "9.857195240840152\n",
            "12.934313478053934\n",
            "27.078045286708157\n",
            "12.325659333878617\n",
            "8.137768307617742\n",
            "9.685150732639984\n",
            "11.190478492372952\n",
            "13.41226116322183\n",
            "7.76283816707899\n",
            "11.149383520495446\n",
            "14.3723198746535\n",
            "9.77837899140889\n",
            "13.93684919569934\n",
            "11.785823794104605\n",
            "13.08810110523887\n",
            "7.936449900707011\n",
            "10.84792690468035\n",
            "11.196597988294853\n",
            "9.71198356876695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RS3mnaIvQnhI"
      },
      "source": [
        "## 1.2\n",
        "Calculate the perplexity for each document in the test set using linear interpolation smoothing method. For determining λs for linear interpolation, you can divide the training data into a new training set (80%) and a held-out set (20%), then using grid search method:\n",
        "Choose ~10 values of λ to test using grid search on held-out data.\n",
        "\n",
        "Some documents in the test set are in Brazilian Portuguese. Identify them as follows: \n",
        "  - Sort by perplexity and set a cut-off threshold. All the documents above this threshold score should be categorized as Brazilian Portuguese. \n",
        "  - Print the file names (from `test_files`) and perplexities of the documents above the threshold\n",
        "\n",
        "    ```\n",
        "        file name, score\n",
        "        file name, score\n",
        "        . . .\n",
        "        file name, score\n",
        "    ```\n",
        "\n",
        "  - Copy this list of filenames and manually annotate them as being correctly or incorrectly labeled as Portuguese.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN-n2iHqS32e",
        "colab_type": "text"
      },
      "source": [
        "## **Please double click on the tab below to have an expanded view in order**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyCRMjLKV8Qv",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "67       cg04           7.607644        English \n",
        "209      cf13           7.762838        English \n",
        "132      cf26           7.846112        English \n",
        "11       ce21           7.878220        English \n",
        "117      ce24           7.904342        English \n",
        "52       ce17           7.921768        English \n",
        "216      cf27           7.936450        English \n",
        "205      cd13           8.137768        English \n",
        "124      cg11           8.174361        English \n",
        "160      cd01           8.203411        English \n",
        "41       cf06           8.216636        English \n",
        "118      ce08           8.276184        English \n",
        "31       ce19           8.292702        English \n",
        "8        cf07           8.316010        English \n",
        "147      ce02           8.320410        English \n",
        "81       ce28           8.365333        English \n",
        "122      cg05           8.395723        English \n",
        "7        cg09           8.427348        English \n",
        "101      cf36           8.532034        English \n",
        "33       cf43           8.585147        English \n",
        "191      cd11           8.587983        English \n",
        "76       ce20           8.674718        English \n",
        "151      cd07           8.727451        English \n",
        "93       cd04           8.736486        English \n",
        "181      cb10           8.846665        English \n",
        "27       cf37           8.887263        English \n",
        "104      ce29           8.888606        English \n",
        "90       cb08           8.928633        English \n",
        "185      cf42           8.968367        English \n",
        "15       ce15           9.008045        English \n",
        "183      cf44           9.030851        English \n",
        "92       ce16           9.040102        English \n",
        "91       cf48           9.045551        English \n",
        "38       cf12           9.046061        English \n",
        "125      cf33           9.099066        English \n",
        "150      cf04           9.133517        English \n",
        "102      cf03           9.140057        English \n",
        "99       cd17           9.216462        English \n",
        "73       cf11           9.226338        English \n",
        "88       cf31           9.239302        English \n",
        "53       cf39           9.251380        English \n",
        "97       ce06           9.252108        English \n",
        "112      cb09           9.301730        English \n",
        "20       ce30           9.438660        English \n",
        "198      ce11           9.446291        English \n",
        "16       cd02           9.475038        English \n",
        "178      ca35           9.476882        English \n",
        "94       cg01           9.528356        English \n",
        "24       cf34           9.580270        English \n",
        "95       cf01           9.582123        English \n",
        "184      cg02           9.602060        English \n",
        "110      cf21           9.641537        English \n",
        "167      cd09           9.666186        English \n",
        "108      ce32           9.684026        English \n",
        "206      cf08           9.685151        English \n",
        "149      ce03           9.701251        English \n",
        "49       cd12           9.711636        English \n",
        "219      ca44           9.711984        English \n",
        "156      cf45           9.722043        English \n",
        "70       cd10           9.723633        English \n",
        "212      cf38           9.778379        English \n",
        "144      cd05           9.785918        English \n",
        "75       cf19           9.817012        English \n",
        "22       ce33           9.848852        English \n",
        "201      cb17           9.857195        English \n",
        "25       ce23           9.873323        English \n",
        "169      cg10           9.883288        English \n",
        "157      ce14           9.889469        English \n",
        "140      ca38           9.921090        English \n",
        "116      ce36           9.944183        English \n",
        "131      cd15           9.949579        English \n",
        "42       ce27          10.004585        English \n",
        "138      cf15          10.007910        English \n",
        "109      ce34          10.093416        English \n",
        "85       cb13          10.120943        English \n",
        "54       cf47          10.123208        English \n",
        "196      cd16          10.155332        English \n",
        "114      cb03          10.174852        English \n",
        "171      cc13          10.182947        English \n",
        "145      ce25          10.218851        English \n",
        "120      cb04          10.272351        English \n",
        "48       cd06          10.280459        English \n",
        "105      cb22          10.288331        English \n",
        "148      ce26          10.289340        English \n",
        "189      cf23          10.312102        English \n",
        "98       ce35          10.321920        English \n",
        "4        cb21          10.334058        English \n",
        "165      ca36          10.346784        English \n",
        "9        cb14          10.382609        English \n",
        "77       ca08          10.457917        English \n",
        "65       ce04          10.471021        English \n",
        "115      cb19          10.532577        English \n",
        "176      cf28          10.547691        English \n",
        "143      cc06          10.574119        English \n",
        "162      cf02          10.587063        English \n",
        "159      ce31          10.588922        English \n",
        "166      cf40          10.606168        English \n",
        "199      cf16          10.614876        English \n",
        "113      cb23          10.619955        English \n",
        "72       cf24          10.621813        English \n",
        "6        cd08          10.690278        English \n",
        "163      cc16          10.716301        English \n",
        "74       cd14          10.716817        English \n",
        "154      cf25          10.731328        English \n",
        "96       cb01          10.731821        English \n",
        "62       ce07          10.738781        English \n",
        "197      cb15          10.777816        English \n",
        "57       cg03          10.794390        English \n",
        "2        cf14          10.813909        English \n",
        "217      cb07          10.847927        English \n",
        "111      cb16          10.885428        English \n",
        "82       cb20          10.892710        English \n",
        "195      cf09          10.897506        English \n",
        "59       cf22          10.963097        English \n",
        "89       cb27          11.023990        English \n",
        "21       ce22          11.029165        English \n",
        "190      ce13          11.029813        English \n",
        "71       cc03          11.051312        English \n",
        "200      cf35          11.060439        English \n",
        "17       cb18          11.093115        English \n",
        "210      ca05          11.149384        English \n",
        "66       cf10          11.159860        English \n",
        "207      cf18          11.190478        English \n",
        "218      cf30          11.196598        English \n",
        "192      cc17          11.202068        English \n",
        "5        cb05          11.203920        English \n",
        "161      cc02          11.207150        English \n",
        "137      ca43          11.227175        English \n",
        "121      cc05          11.241235        English \n",
        "23       ca28          11.265702        English \n",
        "142      ca03          11.413440        English \n",
        "32       ce18          11.441163        English \n",
        "47       cg08          11.442337        English \n",
        "127      ca41          11.481596        English \n",
        "172      cg07          11.625483        English \n",
        "155      ce01          11.690457        English \n",
        "46       cf20          11.736039        English \n",
        "14       cf32          11.766587        English \n",
        "214      cc08          11.785824        English \n",
        "86       ca34          11.854519        English \n",
        "80       ce10          11.970081        English \n",
        "13       ca04          11.995724        English \n",
        "30       cc12          12.043241        English \n",
        "129      cb02          12.083724        English \n",
        "35       cc14          12.224289        English \n",
        "87       cb24          12.225326        English \n",
        "136      cb12          12.239529        English \n",
        "139      cf46          12.244886        English \n",
        "3        cc07          12.301324        English \n",
        "164      cf05          12.306229        English \n",
        "204      cc01          12.325659        English \n",
        "1        cf41          12.346587        English \n",
        "39       cb25          12.348566        English \n",
        "84       cg06          12.349902        English \n",
        "134      cc10          12.530201        English \n",
        "63       cc04          12.533545        English \n",
        "51       ca20          12.587932        English \n",
        "26       cb06          12.595388        English \n",
        "0        cd03          12.602390        English \n",
        "187      ca19          12.689184        English \n",
        "194      ca01          12.731162        English \n",
        "123      cb26          12.835588        English \n",
        "202      ca26          12.934313        English \n",
        "60       ca32          12.937487        English \n",
        "64       cc11          13.017470        English \n",
        "128      ca14          13.044402        English \n",
        "215      ca33          13.088101        English \n",
        "141      ca10          13.099486        English \n",
        "177      ca06          13.105373        English \n",
        "173      ce05          13.164509        English \n",
        "126      ca09          13.232818        English \n",
        "10       ca30          13.284228        English \n",
        "208      ca39          13.412261        English \n",
        "43       ca22          13.462177        English \n",
        "19       ca12          13.528705        English \n",
        "58       ca21          13.529430        English \n",
        "56       ca27          13.561162        English \n",
        "174      ca07          13.601775        English \n",
        "133      ce12          13.638902        English \n",
        "193      ca15          13.831988        English \n",
        "55       ca37          13.880419        English \n",
        "213      ca29          13.936849        English \n",
        "28       ca42          14.079374        English \n",
        "186      ca13          14.212800        English \n",
        "78       cc09          14.215237        English \n",
        "153      cb11          14.260719        English \n",
        "37       cf17          14.313950        English \n",
        "188      ca02          14.333278        English \n",
        "119      ca24          14.337879        English \n",
        "211      ca25          14.372320        English \n",
        "106      cf29          14.503452        English \n",
        "135      ca40          14.697287        English \n",
        "180      cc15          15.348686        English \n",
        "79       ca11          15.492125        English \n",
        "146      ca23          16.583751        English \n",
        "68       ca31          16.708870        English \n",
        "44       ca16          17.994697        English \n",
        "36       ca17          18.949265        English \n",
        "61       ca18          21.102725        English \n",
        "40       ce09          21.436236        English \n",
        "203   ag94fe1.txt          27.078045       Portugese\n",
        "18   ag94ja11.txt          29.275315       Portugese\n",
        "107  br94ab02.txt          30.196547       Portugese\n",
        "69    ag94mr1.txt          30.415082       Portugese\n",
        "29   br94ju01.txt          30.605785       Portugese\n",
        "12   ag94ab12.txt          31.078740       Portugese\n",
        "103  ag94no01.txt          31.179321       Portugese\n",
        "34   br94jl01.txt          31.190554       Portugese\n",
        "50   ag94jl12.txt          31.344721       Portugese\n",
        "170  br94de01.txt          31.424423       Portugese\n",
        "152  br94ja04.txt          31.668146       Portugese\n",
        "158  ag94ma03.txt          31.704502       Portugese\n",
        "175  ag94ou04.txt          31.788427       Portugese\n",
        "83   ag94de06.txt          32.058848       Portugese\n",
        "130  ag94ju07.txt          32.076658       Portugese\n",
        "168  ag94ag02.txt          32.241798       Portugese\n",
        "182  br94ag01.txt          32.757263       Portugese\n",
        "45    br94fe1.txt          32.972234       Portugese\n",
        "179  br94ma01.txt          33.606311       Portugese\n",
        "100  ag94se06.txt          34.076098       Portugese"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QQF4HhQGOZD8",
        "outputId": "49386da4-5ef0-4e5a-c09c-f7256f16b6fb",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame()\n",
        "df[\"file_name\"]=test_files\n",
        "df[\"Perplexity Values\"]=pp\n",
        "df=df.sort_values(by='Perplexity Values',axis=0)\n",
        "threshold=22\n",
        "df[\"Predicted Label\"]=df[\"Perplexity Values\"].apply(lambda x: \"English \" if x<threshold else \"Portugese\")\n",
        "print(\"Given below are the non english files\")\n",
        "print(df[df[\"Perplexity Values\"]>threshold])# Your code here"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Given below are the non english files\n",
            "        file_name  Perplexity Values Predicted Label\n",
            "203   ag94fe1.txt          27.078045       Portugese\n",
            "18   ag94ja11.txt          29.275315       Portugese\n",
            "107  br94ab02.txt          30.196547       Portugese\n",
            "69    ag94mr1.txt          30.415082       Portugese\n",
            "29   br94ju01.txt          30.605785       Portugese\n",
            "12   ag94ab12.txt          31.078740       Portugese\n",
            "103  ag94no01.txt          31.179321       Portugese\n",
            "34   br94jl01.txt          31.190554       Portugese\n",
            "50   ag94jl12.txt          31.344721       Portugese\n",
            "170  br94de01.txt          31.424423       Portugese\n",
            "152  br94ja04.txt          31.668146       Portugese\n",
            "158  ag94ma03.txt          31.704502       Portugese\n",
            "175  ag94ou04.txt          31.788427       Portugese\n",
            "83   ag94de06.txt          32.058848       Portugese\n",
            "130  ag94ju07.txt          32.076658       Portugese\n",
            "168  ag94ag02.txt          32.241798       Portugese\n",
            "182  br94ag01.txt          32.757263       Portugese\n",
            "45    br94fe1.txt          32.972234       Portugese\n",
            "179  br94ma01.txt          33.606311       Portugese\n",
            "100  ag94se06.txt          34.076098       Portugese\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzhDMdRfUZFx",
        "colab_type": "text"
      },
      "source": [
        "file name            perplexity      Predicted label       True Label\n",
        "\n",
        "ag94fe1.txt          27.078045       Portugese              Portugese\n",
        "\n",
        "ag94ja11.txt          29.275315       Portugese             Portugese\n",
        "\n",
        "br94ab02.txt          30.196547       Portugese            Portugese\n",
        "\n",
        "ag94mr1.txt          30.415082       Portugese               Portugese\n",
        "\n",
        "br94ju01.txt          30.605785       Portugese             Portugese\n",
        "\n",
        "ag94ab12.txt          31.078740       Portugese              Portugese\n",
        "\n",
        "ag94no01.txt          31.179321       Portugese              Portugese\n",
        "\n",
        "br94jl01.txt          31.190554       Portugese               Portugese\n",
        "\n",
        "ag94jl12.txt          31.344721       Portugese              Portugese\n",
        "\n",
        "br94de01.txt          31.424423       Portugese               Portugese\n",
        "\n",
        "br94ja04.txt          31.668146       Portugese              Portugese\n",
        "\n",
        "ag94ma03.txt          31.704502       Portugese               Portugese\n",
        "\n",
        "ag94ou04.txt          31.788427       Portugese               Portugese\n",
        "\n",
        "ag94de06.txt          32.058848       Portugese               Portugese\n",
        "\n",
        "ag94ju07.txt          32.076658       Portugese              Portugese\n",
        "\n",
        "ag94ag02.txt          32.241798       Portugese                Portugese\n",
        "\n",
        "br94ag01.txt          32.757263       Portugese               Portugese\n",
        "\n",
        "br94fe1.txt          32.972234       Portugese                Portugese\n",
        "\n",
        "br94ma01.txt          33.606311       Portugese              Portugese\n",
        "\n",
        "ag94se06.txt          34.076098       Portugese                 Portugese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcqSReF8V8Q0",
        "colab_type": "text"
      },
      "source": [
        "## English has perplexity between 7-21 while Portugese has perplexity between 27-34"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aQl2u_giVW5e"
      },
      "source": [
        "## 1.3\n",
        "Build a trigram language model with add-λ smoothing (use λ = 0.1).\n",
        "\n",
        "Sort the test documents by perplexity and perform a check for Brazilian Portuguese documents as above:\n",
        "\n",
        "  - Observe the perplexity scores and set a cut-off threshold. All the documents above this threshold score should be categorized as Brazilian Portuguese. \n",
        "  - Print the file names and perplexities of the documents above the threshold\n",
        "\n",
        "  ```\n",
        "      file name, score\n",
        "      file name, score\n",
        "      . . .\n",
        "      file name, score\n",
        "  ```\n",
        "\n",
        "  - Copy this list of filenames and manually annotate them for correctness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tFq1ECgDI6QG"
      },
      "source": [
        "file_name  Perplexity Values Predicted Label\n",
        "67       cg04           7.304036        English \n",
        "209      cf13           7.449559        English \n",
        "132      cf26           7.494317        English \n",
        "11       ce21           7.581537        English \n",
        "216      cf27           7.602170        English \n",
        "52       ce17           7.604204        English \n",
        "117      ce24           7.644647        English \n",
        "160      cd01           7.746349        English \n",
        "124      cg11           7.846200        English \n",
        "205      cd13           7.855948        English \n",
        "41       cf06           7.878799        English \n",
        "8        cf07           7.983433        English \n",
        "31       ce19           8.018265        English \n",
        "118      ce08           8.033742        English \n",
        "7        cg09           8.045040        English \n",
        "191      cd11           8.078555        English \n",
        "147      ce02           8.083724        English \n",
        "81       ce28           8.159405        English \n",
        "101      cf36           8.162105        English \n",
        "122      cg05           8.172458        English \n",
        "151      cd07           8.184022        English \n",
        "33       cf43           8.241441        English \n",
        "93       cd04           8.265286        English \n",
        "90       cb08           8.334354        English \n",
        "76       ce20           8.336455        English \n",
        "27       cf37           8.422766        English \n",
        "104      ce29           8.444962        English \n",
        "38       cf12           8.459403        English \n",
        "181      cb10           8.474488        English \n",
        "185      cf42           8.482337        English \n",
        "15       ce15           8.601110        English \n",
        "91       cf48           8.621589        English \n",
        "88       cf31           8.654008        English \n",
        "183      cf44           8.715900        English \n",
        "150      cf04           8.729199        English \n",
        "99       cd17           8.756755        English \n",
        "102      cf03           8.764841        English \n",
        "125      cf33           8.775444        English \n",
        "112      cb09           8.810848        English \n",
        "92       ce16           8.823718        English \n",
        "97       ce06           8.827657        English \n",
        "73       cf11           8.939385        English \n",
        "167      cd09           9.002029        English \n",
        "53       cf39           9.019933        English \n",
        "16       cd02           9.070546        English \n",
        "94       cg01           9.074175        English \n",
        "49       cd12           9.155629        English \n",
        "178      ca35           9.157226        English \n",
        "144      cd05           9.203840        English \n",
        "95       cf01           9.213021        English \n",
        "70       cd10           9.214313        English \n",
        "184      cg02           9.239399        English \n",
        "198      ce11           9.257273        English \n",
        "206      cf08           9.267367        English \n",
        "149      ce03           9.277927        English \n",
        "108      ce32           9.283809        English \n",
        "156      cf45           9.306165        English \n",
        "219      ca44           9.311409        English \n",
        "212      cf38           9.333878        English \n",
        "22       ce33           9.339820        English \n",
        "196      cd16           9.368256        English \n",
        "201      cb17           9.375684        English \n",
        "116      ce36           9.395724        English \n",
        "169      cg10           9.410946        English \n",
        "25       ce23           9.426030        English \n",
        "20       ce30           9.445501        English \n",
        "131      cd15           9.526335        English \n",
        "24       cf34           9.579629        English \n",
        "138      cf15           9.583606        English \n",
        "48       cd06           9.588310        English \n",
        "98       ce35           9.627246        English \n",
        "54       cf47           9.666189        English \n",
        "189      cf23           9.675814        English \n",
        "171      cc13           9.676550        English \n",
        "114      cb03           9.683189        English \n",
        "105      cb22           9.692627        English \n",
        "75       cf19           9.695514        English \n",
        "110      cf21           9.714171        English \n",
        "85       cb13           9.746956        English \n",
        "166      cf40           9.772725        English \n",
        "157      ce14           9.786911        English \n",
        "9        cb14           9.796737        English \n",
        "4        cb21           9.812612        English \n",
        "159      ce31           9.835854        English \n",
        "120      cb04           9.845955        English \n",
        "165      ca36           9.867804        English \n",
        "176      cf28           9.943745        English \n",
        "42       ce27           9.946855        English \n",
        "148      ce26           9.957617        English \n",
        "140      ca38           9.989771        English \n",
        "57       cg03          10.000188        English \n",
        "143      cc06          10.006471        English \n",
        "65       ce04          10.018981        English \n",
        "77       ca08          10.031330        English \n",
        "145      ce25          10.057300        English \n",
        "115      cb19          10.061790        English \n",
        "162      cf02          10.073499        English \n",
        "199      cf16          10.073657        English \n",
        "109      ce34          10.074691        English \n",
        "6        cd08          10.108209        English \n",
        "113      cb23          10.110773        English \n",
        "72       cf24          10.127622        English \n",
        "62       ce07          10.132447        English \n",
        "74       cd14          10.146853        English \n",
        "2        cf14          10.155125        English \n",
        "96       cb01          10.160223        English \n",
        "195      cf09          10.161904        English \n",
        "197      cb15          10.194039        English \n",
        "89       cb27          10.237407        English \n",
        "163      cc16          10.266433        English \n",
        "154      cf25          10.294652        English \n",
        "217      cb07          10.317523        English \n",
        "210      ca05          10.320732        English \n",
        "111      cb16          10.334316        English \n",
        "207      cf18          10.391376        English \n",
        "161      cc02          10.413781        English \n",
        "17       cb18          10.418634        English \n",
        "59       cf22          10.456223        English \n",
        "71       cc03          10.470589        English \n",
        "190      ce13          10.472309        English \n",
        "82       cb20          10.501107        English \n",
        "66       cf10          10.574416        English \n",
        "121      cc05          10.610752        English \n",
        "23       ca28          10.635858        English \n",
        "5        cb05          10.641327        English \n",
        "32       ce18          10.697165        English \n",
        "21       ce22          10.713839        English \n",
        "137      ca43          10.734768        English \n",
        "192      cc17          10.741346        English \n",
        "218      cf30          10.805893        English \n",
        "46       cf20          10.819290        English \n",
        "14       cf32          10.945491        English \n",
        "172      cg07          10.994494        English \n",
        "127      ca41          11.087999        English \n",
        "47       cg08          11.116685        English \n",
        "13       ca04          11.116924        English \n",
        "214      cc08          11.119927        English \n",
        "142      ca03          11.135558        English \n",
        "155      ce01          11.148113        English \n",
        "200      cf35          11.260124        English \n",
        "129      cb02          11.381932        English \n",
        "86       ca34          11.419067        English \n",
        "30       cc12          11.419384        English \n",
        "35       cc14          11.517960        English \n",
        "136      cb12          11.523518        English \n",
        "3        cc07          11.621524        English \n",
        "80       ce10          11.677504        English \n",
        "0        cd03          11.701323        English \n",
        "134      cc10          11.707887        English \n",
        "63       cc04          11.718321        English \n",
        "164      cf05          11.761819        English \n",
        "87       cb24          11.776969        English \n",
        "1        cf41          11.865708        English \n",
        "26       cb06          11.869949        English \n",
        "139      cf46          11.872384        English \n",
        "187      ca19          11.969772        English \n",
        "39       cb25          11.983505        English \n",
        "84       cg06          11.984293        English \n",
        "204      cc01          11.987018        English \n",
        "51       ca20          12.104867        English \n",
        "123      cb26          12.150470        English \n",
        "194      ca01          12.168731        English \n",
        "177      ca06          12.182307        English \n",
        "64       cc11          12.233150        English \n",
        "141      ca10          12.245598        English \n",
        "60       ca32          12.311206        English \n",
        "202      ca26          12.385267        English \n",
        "126      ca09          12.391217        English \n",
        "173      ce05          12.422467        English \n",
        "215      ca33          12.445762        English \n",
        "43       ca22          12.489832        English \n",
        "10       ca30          12.513109        English \n",
        "56       ca27          12.560387        English \n",
        "128      ca14          12.658197        English \n",
        "174      ca07          12.776310        English \n",
        "78       cc09          12.825969        English \n",
        "19       ca12          13.053244        English \n",
        "208      ca39          13.084837        English \n",
        "58       ca21          13.154931        English \n",
        "55       ca37          13.161555        English \n",
        "153      cb11          13.170134        English \n",
        "119      ca24          13.196285        English \n",
        "188      ca02          13.214838        English \n",
        "213      ca29          13.282081        English \n",
        "28       ca42          13.288785        English \n",
        "133      ce12          13.290805        English \n",
        "193      ca15          13.484348        English \n",
        "37       cf17          13.622221        English \n",
        "211      ca25          13.761926        English \n",
        "106      cf29          13.765441        English \n",
        "186      ca13          13.797593        English \n",
        "135      ca40          13.854586        English \n",
        "79       ca11          14.935484        English \n",
        "180      cc15          15.065617        English \n",
        "146      ca23          15.456654        English \n",
        "68       ca31          15.697082        English \n",
        "44       ca16          17.139938        English \n",
        "36       ca17          17.880277        English \n",
        "40       ce09          19.294780        English \n",
        "61       ca18          19.738884        English \n",
        "203   ag94fe1.txt          28.606582       Portugese\n",
        "107  br94ab02.txt          30.531663       Portugese\n",
        "34   br94jl01.txt          30.885890       Portugese\n",
        "29   br94ju01.txt          30.921611       Portugese\n",
        "18   ag94ja11.txt          31.043050       Portugese\n",
        "170  br94de01.txt          31.227055       Portugese\n",
        "152  br94ja04.txt          31.281177       Portugese\n",
        "12   ag94ab12.txt          31.295896       Portugese\n",
        "103  ag94no01.txt          31.400614       Portugese\n",
        "45    br94fe1.txt          31.615863       Portugese\n",
        "69    ag94mr1.txt          31.810722       Portugese\n",
        "175  ag94ou04.txt          31.839155       Portugese\n",
        "50   ag94jl12.txt          31.850135       Portugese\n",
        "130  ag94ju07.txt          31.901756       Portugese\n",
        "182  br94ag01.txt          32.037548       Portugese\n",
        "158  ag94ma03.txt          32.210307       Portugese\n",
        "168  ag94ag02.txt          32.494577       Portugese\n",
        "83   ag94de06.txt          32.653609       Portugese\n",
        "100  ag94se06.txt          33.076175       Portugese\n",
        "179  br94ma01.txt          33.539113       Portugese"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zzoHHMv6ceaj",
        "colab": {}
      },
      "source": [
        "corpus=[]\n",
        "for i in range(len(train)):\n",
        "  for j in range(len(train[i])):\n",
        "    corpus.append((re.sub(\"[\\x1a]+\", ' ',\" \".join(train[i][j])).lstrip().rstrip()))\n",
        "\n",
        "c1,c2,c3=dict(),dict(),dict()\n",
        "\n",
        "cv1=CountVectorizer(ngram_range=(1,1),analyzer='char')\n",
        "x1=cv1.fit_transform(corpus)\n",
        "\n",
        "t1=np.array(np.sum(x1,axis=0))[0]\n",
        "for i,name in enumerate(cv1.get_feature_names()):\n",
        "  c1[name]=t1[i] # word and count\n",
        " \n",
        "#removing unigrams that have a count <100\n",
        "rep=[]\n",
        "tot=0\n",
        "for a in c1:\n",
        "  if c1[a]<100:\n",
        "    tot +=c1[a]\n",
        "    rep.append(a)\n",
        "\n",
        "c1['µ']=tot # unknown token since it doesnt appear int the docs\n",
        "\n",
        "for i in rep:\n",
        "  del c1[i]\n",
        "\n",
        "corpus2=[]\n",
        "for sent in corpus:\n",
        "  corpus2.append(re.sub('[/$/&>/`/æ/è/î/~/@/=/</+/%]',\"µ\" ,sent))\n",
        "\n",
        "# removed tokens with values less than 100 and replaced with special token\n",
        "cv1=CountVectorizer(ngram_range=(1,1),analyzer='char')\n",
        "cv2=CountVectorizer(ngram_range=(2,2),analyzer='char')\n",
        "cv3=CountVectorizer(ngram_range=(3,3),analyzer='char')\n",
        "x1=cv1.fit_transform(corpus2)\n",
        "x2=cv2.fit_transform(corpus2)\n",
        "x3=cv3.fit_transform(corpus2)\n",
        "\n",
        "t1=np.array(np.sum(x1,axis=0))[0]\n",
        "for i,name in enumerate(cv1.get_feature_names()):\n",
        "  c1[name]=t1[i] \n",
        "\n",
        "t2=np.array(np.sum(x2,axis=0))[0]\n",
        "for i,name in enumerate(cv2.get_feature_names()):\n",
        "  c2[name]=t2[i]\n",
        "\n",
        "t3=np.array(np.sum(x3,axis=0))[0]\n",
        "for i,name in enumerate(cv3.get_feature_names()):\n",
        "  c3[name]=t3[i]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yGUSE-gSffuu",
        "colab": {}
      },
      "source": [
        "def generate_trigram_sent(sent):\n",
        "    tri=[]\n",
        "    for j in range(len(sent)-3):\n",
        "      tri.append(sent[j:j+3])\n",
        "    return tri\n",
        "\n",
        "\n",
        "\n",
        "def tri_smoothing(token,a3,a2,a1,lam):\n",
        "  if token not in set(a3.keys()):\n",
        "    num=lam\n",
        "  elif token in set(a3.keys()) :\n",
        "    num=lam+a3[token]\n",
        "  if token[:2] not in set(a2.keys()):\n",
        "    den=lam*len(a1)  # len(a1) represents vocabulary\n",
        "  elif token[:2] in set(a2.keys()):\n",
        "    den=(lam*len(a1)) + a2[token[:2]]\n",
        "  return(num/den)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q55nj3_zgg3p",
        "colab": {}
      },
      "source": [
        "def perplexity(corp,a1,a2,a3,lam): # corp can be the whole test set or dev set  \n",
        "    perplexity=[]\n",
        "    for doc in corp: # picking single documents\n",
        "        #print(\"doc\")\n",
        "    \n",
        "        dd=CountVectorizer(ngram_range=(1,1),analyzer='char')\n",
        "        gg=dd.fit_transform(doc)\n",
        "        tt=dict()\n",
        "        tp1=np.array(np.sum(gg,axis=0))[0]\n",
        "        for i,name in enumerate(dd.get_feature_names()):\n",
        "          tt[name]=tp1[i] # word and count\n",
        "        char=np.array(list(tt.values())).sum() # refers to M # total number of characters in a document\n",
        "\n",
        "        # real calculations begin\n",
        "\n",
        "        log_prob=0\n",
        "        for sent in doc: # refers to each document fro the dev set or test set # loops over all thesentences in the document\n",
        "          trigrams=generate_trigram_sent(sent) # generates trigrams for the given sentence\n",
        "          for tri_gram in trigrams: # loops over all the characters in a sentence\n",
        "              \n",
        "\n",
        "              prob=tri_smoothing(tri_gram,a3,a2,a1,lam)\n",
        "              log_prob += np.log2(prob)\n",
        "\n",
        "        l=log_prob/char\n",
        "        perp=pow(2,-l)\n",
        "        print(perp)\n",
        "        perplexity.append(perp)\n",
        "    return(perplexity)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZKFEhNBNynzT",
        "colab": {}
      },
      "source": [
        "# preparing test set\n",
        "TEST=[]\n",
        "for i in range(len(test)):\n",
        "  k=[]\n",
        "  for j in range(len(test[i])):\n",
        "    k.append((\" \".join(test[i][j])).lstrip().rstrip())\n",
        "  TEST.append(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8GZEkRZqzb8Z",
        "outputId": "f968d458-10b9-47f8-d894-2a90f410cc66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "perp=perplexity(TEST,c1,c2,c3,0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.701323018776531\n",
            "11.865708032142411\n",
            "10.155124841480799\n",
            "11.62152445257162\n",
            "9.812612435628473\n",
            "10.641326910534529\n",
            "10.108208651716497\n",
            "8.045040098759397\n",
            "7.98343304549849\n",
            "9.796736749676292\n",
            "12.513108799810345\n",
            "7.581537011881531\n",
            "31.295896069427805\n",
            "11.116923763996232\n",
            "10.945491470446333\n",
            "8.601109788178563\n",
            "9.070545837868497\n",
            "10.418634167058752\n",
            "31.04304956905218\n",
            "13.053243765548137\n",
            "9.44550073309761\n",
            "10.71383871484805\n",
            "9.339820493970603\n",
            "10.635858162697854\n",
            "9.57962916769351\n",
            "9.42602952082602\n",
            "11.869948967428959\n",
            "8.422765558190747\n",
            "13.288785457815964\n",
            "30.92161106154445\n",
            "11.419384013153264\n",
            "8.01826538392935\n",
            "10.697164966162148\n",
            "8.24144097261492\n",
            "30.88588998096397\n",
            "11.517959661315333\n",
            "17.88027687330908\n",
            "13.622221091257767\n",
            "8.459403146755344\n",
            "11.983504933450977\n",
            "19.294780139202846\n",
            "7.878798964939564\n",
            "9.94685473443481\n",
            "12.48983165525897\n",
            "17.139938149166717\n",
            "31.61586305567981\n",
            "10.819290233381475\n",
            "11.116685028217018\n",
            "9.588310345720345\n",
            "9.155629273611313\n",
            "31.85013491129407\n",
            "12.1048672342839\n",
            "7.60420351188095\n",
            "9.019932535533114\n",
            "9.666189090494107\n",
            "13.161555428182808\n",
            "12.560387215408703\n",
            "10.000188348551456\n",
            "13.154930765409722\n",
            "10.456223361276685\n",
            "12.311205652773975\n",
            "19.738883977174613\n",
            "10.132446937956365\n",
            "11.718321030762386\n",
            "12.233149641405682\n",
            "10.018980746928122\n",
            "10.574416346528368\n",
            "7.304036153638543\n",
            "15.697082263794082\n",
            "31.810722099109714\n",
            "9.21431277910868\n",
            "10.47058886050439\n",
            "10.127622321225697\n",
            "8.939384628487327\n",
            "10.14685334375696\n",
            "9.695514336662576\n",
            "8.336454529225822\n",
            "10.031330123594195\n",
            "12.825969209766829\n",
            "14.93548354671891\n",
            "11.6775037282987\n",
            "8.159405380264674\n",
            "10.501106716619343\n",
            "32.65360930279462\n",
            "11.984292909209554\n",
            "9.746955793876625\n",
            "11.419066731288357\n",
            "11.776968638981167\n",
            "8.654007606487262\n",
            "10.237406513392466\n",
            "8.334353594692118\n",
            "8.62158852381714\n",
            "8.8237182828443\n",
            "8.265285873287933\n",
            "9.074174735155962\n",
            "9.213020615331319\n",
            "10.160222575053771\n",
            "8.82765695671676\n",
            "9.62724628080219\n",
            "8.756754785001645\n",
            "33.076174823381734\n",
            "8.162105375859603\n",
            "8.764841007957447\n",
            "31.40061411802855\n",
            "8.44496223156109\n",
            "9.692626968856459\n",
            "13.765440978746492\n",
            "30.531662962381283\n",
            "9.283808871723801\n",
            "10.074690841649064\n",
            "9.7141706893224\n",
            "10.334316026475435\n",
            "8.810848151329491\n",
            "10.110773260461315\n",
            "9.683189024851588\n",
            "10.061790465053585\n",
            "9.395723574748404\n",
            "7.644646605875719\n",
            "8.033742047083507\n",
            "13.196285314805573\n",
            "9.845955159300622\n",
            "10.610751727385361\n",
            "8.172458472591371\n",
            "12.150470481290569\n",
            "7.846199966664202\n",
            "8.77544433673427\n",
            "12.391216842632474\n",
            "11.08799948256403\n",
            "12.65819739617137\n",
            "11.381932310737218\n",
            "31.901756276255682\n",
            "9.526335253929648\n",
            "7.494317437938818\n",
            "13.290805068154791\n",
            "11.707886833158069\n",
            "13.854585675778534\n",
            "11.523518330575003\n",
            "10.734768075009649\n",
            "9.583605952719473\n",
            "11.872383918798436\n",
            "9.989770740003753\n",
            "12.245598229969053\n",
            "11.135558341330324\n",
            "10.006470716890878\n",
            "9.203839702045345\n",
            "10.05729984513817\n",
            "15.456654435639486\n",
            "8.083723511408778\n",
            "9.9576169051671\n",
            "9.277927081498921\n",
            "8.72919932386642\n",
            "8.184021994494536\n",
            "31.28117745776208\n",
            "13.170134219000271\n",
            "10.294652253633414\n",
            "11.148112603700264\n",
            "9.30616546184801\n",
            "9.786911220234767\n",
            "32.210307062291484\n",
            "9.835854148122083\n",
            "7.746349292648707\n",
            "10.413780563232326\n",
            "10.073499157137482\n",
            "10.266433296561187\n",
            "11.761819375880256\n",
            "9.867803962335636\n",
            "9.772725424088353\n",
            "9.002028524484128\n",
            "32.49457701430636\n",
            "9.410945567624378\n",
            "31.227054951497074\n",
            "9.676549719906179\n",
            "10.994493538079123\n",
            "12.422466898974706\n",
            "12.776310109162154\n",
            "31.83915462850352\n",
            "9.94374497547856\n",
            "12.18230749116129\n",
            "9.157226361165169\n",
            "33.53911348106183\n",
            "15.065617025686628\n",
            "8.47448775016306\n",
            "32.03754821614487\n",
            "8.715900284095317\n",
            "9.23939855228857\n",
            "8.482336533796644\n",
            "13.797592873779253\n",
            "11.969772346370258\n",
            "13.214837514263177\n",
            "9.675814229819022\n",
            "10.472308818357831\n",
            "8.078554941033927\n",
            "10.741346039959094\n",
            "13.484348302633123\n",
            "12.168731231252732\n",
            "10.161904350271064\n",
            "9.368256268301181\n",
            "10.19403856321388\n",
            "9.25727298851747\n",
            "10.073657228600384\n",
            "11.260124230595304\n",
            "9.375684240670441\n",
            "12.385267250571841\n",
            "28.60658172120042\n",
            "11.987018279173542\n",
            "7.85594760471472\n",
            "9.267366823465792\n",
            "10.391375591606346\n",
            "13.084837361004892\n",
            "7.449559092710462\n",
            "10.320731631251212\n",
            "13.761925930649001\n",
            "9.333877961732597\n",
            "13.28208102756869\n",
            "11.119927117129274\n",
            "12.445762403863041\n",
            "7.602170343105921\n",
            "10.317523377183727\n",
            "10.805893045089292\n",
            "9.311408738860097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ERcSej2Hzhnq",
        "colab": {}
      },
      "source": [
        "df1=pd.DataFrame()\n",
        "df1[\"file_name\"]=test_files\n",
        "df1[\"Perplexity Values\"]=perp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qUE42Hpgzn5J",
        "colab": {}
      },
      "source": [
        "df1=df1.sort_values(by='Perplexity Values',axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "huWmOHe2IRY8",
        "outputId": "16c52b84-6385-4ac9-b174-dbbe432aa8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "threshold=22\n",
        "df1[\"Predicted Label\"]=df1[\"Perplexity Values\"].apply(lambda x: \"English \" if x<threshold else \"Portugese\")\n",
        "print(\"Given below are thenon english files\")\n",
        "print(df1[df1[\"Perplexity Values\"]>threshold])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Given below are thenon english files\n",
            "        file_name  Perplexity Values Predicted Label\n",
            "203   ag94fe1.txt          28.606582       Portugese\n",
            "107  br94ab02.txt          30.531663       Portugese\n",
            "34   br94jl01.txt          30.885890       Portugese\n",
            "29   br94ju01.txt          30.921611       Portugese\n",
            "18   ag94ja11.txt          31.043050       Portugese\n",
            "170  br94de01.txt          31.227055       Portugese\n",
            "152  br94ja04.txt          31.281177       Portugese\n",
            "12   ag94ab12.txt          31.295896       Portugese\n",
            "103  ag94no01.txt          31.400614       Portugese\n",
            "45    br94fe1.txt          31.615863       Portugese\n",
            "69    ag94mr1.txt          31.810722       Portugese\n",
            "175  ag94ou04.txt          31.839155       Portugese\n",
            "50   ag94jl12.txt          31.850135       Portugese\n",
            "130  ag94ju07.txt          31.901756       Portugese\n",
            "182  br94ag01.txt          32.037548       Portugese\n",
            "158  ag94ma03.txt          32.210307       Portugese\n",
            "168  ag94ag02.txt          32.494577       Portugese\n",
            "83   ag94de06.txt          32.653609       Portugese\n",
            "100  ag94se06.txt          33.076175       Portugese\n",
            "179  br94ma01.txt          33.539113       Portugese\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHTiyOgwVJeC",
        "colab_type": "text"
      },
      "source": [
        "Index file_name  Perplexity Values Predicted Label true label\n",
        "\n",
        "203   ag94fe1.txt          28.606582       Portugese Portugese\n",
        "\n",
        "107  br94ab02.txt          30.531663       Portugese Portugese\n",
        "\n",
        "34   br94jl01.txt          30.885890       Portugese Portugese\n",
        "\n",
        "29   br94ju01.txt          30.921611       Portugese Portugese\n",
        "\n",
        "18   ag94ja11.txt          31.043050       Portugese Portugese\n",
        "\n",
        "170  br94de01.txt          31.227055       Portugese Portugese\n",
        "\n",
        "152  br94ja04.txt          31.281177       Portugese Portugese\n",
        "\n",
        "12   ag94ab12.txt          31.295896       Portugese Portugese\n",
        "\n",
        "103  ag94no01.txt          31.400614       Portugese Portugese\n",
        "\n",
        "45    br94fe1.txt          31.615863       Portugese Portugese\n",
        "\n",
        "69    ag94mr1.txt          31.810722       Portugese Portugese\n",
        "\n",
        "175  ag94ou04.txt          31.839155       Portugese Portugese\n",
        "\n",
        "50   ag94jl12.txt          31.850135       Portugese Portugese\n",
        "\n",
        "130  ag94ju07.txt          31.901756       Portugese Portugese\n",
        "\n",
        "182  br94ag01.txt          32.037548       Portugese Portugese\n",
        "\n",
        "158  ag94ma03.txt          32.210307       Portugese Portugese\n",
        "\n",
        "168  ag94ag02.txt          32.494577       Portugese Portugese\n",
        "\n",
        "83   ag94de06.txt          32.653609       Portugese Portugese\n",
        "\n",
        "100  ag94se06.txt          33.076175       Portugese Portugese\n",
        "\n",
        "179  br94ma01.txt          33.539113       Portugese Portugese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh2EL1cXV8RW",
        "colab_type": "text"
      },
      "source": [
        "## English has a perplexity between 7.3-19.73 while Portugese has perplexity between 28-33"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bqhXTB5TXR25"
      },
      "source": [
        "## 1.4\n",
        "Based on your observation from above questions, compare linear interpolation and add-λ smoothing by listing out their pros and cons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwVhnoXUV8Ra",
        "colab_type": "text"
      },
      "source": [
        "Linear Interpolation and Lambda smoothing has provided similar perplexity values but one can notice that both models perform equally well\n",
        "Advantage of Linear interpolation is that it given weightage to bigrams and unigrams when trigram is missing\n",
        "Disadvantage is Linear interpolation is a time consuming process which takes a lon time to execute\n",
        "Advantage of Lambda smoothing is that its faster."
      ]
    }
  ]
}